output_dir: ~/git/ULTRA/output

dataset:
  class: JointDataset
  graphs: [FB15k237, WN18RR, CoDExMedium]
  root: ~/git/ULTRA/kg-datasets/

moreeval: 
  ind_evalgraphs: [FBIngram:100, WKIngram:100, NLIngram:100]
  evalgraphs: [NELL995, YAGO310, DBpedia100k]
  
model:
  class: Ultra
  relation_model:
    class: NBFNet
    input_dim: 64
    hidden_dims: [64, 64, 64, 64, 64, 64]
    message_func: distmult
    aggregate_func: sum
    short_cut: yes
    layer_norm: yes
  entity_model:
    class: IndNBFNet
    input_dim: 64
    hidden_dims: [64, 64, 64, 64, 64, 64]
    message_func: distmult
    aggregate_func: sum
    short_cut: yes
    layer_norm: yes

task:
  name: MultiGraphPretraining
  num_negative: 512
  strict_negative: yes
  adversarial_temperature: 1
  metric: [mr, mrr, hits@1, hits@3, hits@10]

optimizer:
  class: AdamW
  lr: 5.0e-4

train:
  gpus: {{ gpus }}
  batch_size: 32
  num_epoch: 10
  log_interval: 800
  batch_per_epoch: 8000
  fast_test: 500
  fewshot_train: 0.1
  #logger: wandb